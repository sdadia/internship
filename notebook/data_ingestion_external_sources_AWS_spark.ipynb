{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-20T18:34:09.327423Z",
     "start_time": "2019-03-20T18:34:09.314675Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Ingestion From External Sources - Spark\n",
    "* Generic Format\n",
    "* Special Format - Need Drivers\n",
    "    * Avro\n",
    "    * S3\n",
    "* Relational Database\n",
    "    * Postgres\n",
    "    * MySQL\n",
    "* NoN-Relational Database\n",
    "    * Cassandra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-20T18:24:08.391599Z",
     "start_time": "2019-03-20T18:23:53.961444Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "os.environ[\"PYSPARK_PYTHON\"]=\"/usr/bin/python3\"\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"]=\"/usr/bin/python3\"\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.hadoop:hadoop-aws:2.7.1,com.datastax.spark:spark-cassandra-connector_2.11:2.3.0,mysql:mysql-connector-java:8.0.15 pyspark-shell'\n",
    "\n",
    "\n",
    "spark = SparkSession.builder\\\n",
    "                    .appName('AWS external sources spark')\\\n",
    "                    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-20T18:24:08.399870Z",
     "start_time": "2019-03-20T18:24:08.393258Z"
    }
   },
   "outputs": [],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generic Format - Dont need drivers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-14T17:45:59.588931Z",
     "start_time": "2019-03-14T17:45:59.580794Z"
    }
   },
   "source": [
    "* csv\n",
    "* json\n",
    "* parquet\n",
    "* libsvm\n",
    "* text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.read.<format>(\"<file name>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.write.<format>(\"<file name>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Special Formats - Need Drivers\n",
    "\n",
    "You can include the following packages using **--packages**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Source| Driver Package|\n",
    "|-----------|----------------|\n",
    "|S3        |org.apache.hadoop:hadoop-aws:2.7.1|\n",
    "|Avro       |org.apache.spark:spark-avro_2.11:2.4.0|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S3\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-14T09:15:01.792930Z",
     "start_time": "2019-03-14T09:15:01.558379Z"
    }
   },
   "source": [
    "#### Read\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.<format>(\"s3a://<bucket name>/<file name>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-14T09:16:20.395479Z",
     "start_time": "2019-03-14T09:16:20.062646Z"
    }
   },
   "source": [
    "#### Write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-14T09:16:20.395479Z",
     "start_time": "2019-03-14T09:16:20.062646Z"
    }
   },
   "outputs": [],
   "source": [
    "df.write.<format>(\"s3a://<bucket name>/<file name>\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relational Databases\n",
    "\n",
    "|Source| Driver Package|Driver Name|Standard Port|\n",
    "|-----------|----------------|---------|----|\n",
    "|Postgres   |org.postgresql:postgresql:42.1.1|org.postgresql.Driver|5432\n",
    "|MySQL       |mysql:mysql-connector-java:8.0.13|com.mysql.jdbc.Driver|3306"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-14T18:40:47.414291Z",
     "start_time": "2019-03-14T18:40:47.408601Z"
    }
   },
   "source": [
    "#### Generic Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-14T18:25:02.010503Z",
     "start_time": "2019-03-14T18:25:01.103211Z"
    }
   },
   "outputs": [],
   "source": [
    "spark.read\\\n",
    "      .format(\"jdbc\")\\\n",
    "      .option(\"driver\", \"<driver name>\")\\\n",
    "      .option(\"url\", \"jdbc:<database type>://<ip>:<port>/<dbname>\")\\\n",
    "      .option(\"dbtable\", \"<table>\")\\\n",
    "      .option(\"user\", \"<username>\")\\\n",
    "      .option(\"password\",\"<password>\")\\\n",
    "      .load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generic Write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write\\\n",
    "      .format(\"jdbc\")\\\n",
    "      .option(\"driver\", \"<driver name>\")\\\n",
    "      .option(\"url\", \"jdbc:<databse type>://<ip>:<port>/<db name>\")\\\n",
    "      .option(\"dbtable\", \"<table name>\")\\\n",
    "      .option(\"user\", \"<username>\")\\\n",
    "      .option(\"password\",\"<password>\")\\\n",
    "      .mode(\"overwrite\")\\\n",
    "      .save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Postgres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-14T18:47:27.442911Z",
     "start_time": "2019-03-14T18:47:27.440885Z"
    }
   },
   "source": [
    "#### Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-20T18:28:05.868068Z",
     "start_time": "2019-03-20T18:28:05.836222Z"
    }
   },
   "outputs": [],
   "source": [
    "spark.read\\\n",
    "      .format(\"jdbc\")\\\n",
    "      .option(\"driver\", \"org.postgresql.Driver\")\\\n",
    "      .option(\"url\", \"jdbc:postgresql://<ip>:5432/<dbname>\")\\\n",
    "      .option(\"dbtable\", \"<table>\")\\\n",
    "      .option(\"user\", \"<username>\")\\\n",
    "      .option(\"password\",\"<password>\")\\\n",
    "      .load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-14T18:47:36.461522Z",
     "start_time": "2019-03-14T18:47:36.459132Z"
    }
   },
   "source": [
    "#### Write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write\\\n",
    "      .format(\"jdbc\")\\\n",
    "      .option(\"driver\", \"org.postgresql.Driver\")\\\n",
    "      .option(\"url\", \"jdbc:postgresql://localhost:5432/spark_demo_db\")\\\n",
    "      .option(\"dbtable\", \"my_table\")\\\n",
    "      .option(\"user\", \"sahil\")\\\n",
    "      .option(\"password\",\"12345\")\\\n",
    "      .mode(\"overwrite\")\\\n",
    "      .save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MYSQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-20T18:29:40.718995Z",
     "start_time": "2019-03-20T18:29:39.514435Z"
    }
   },
   "outputs": [],
   "source": [
    "spark.read\\\n",
    "      .format(\"jdbc\")\\\n",
    "      .option(\"driver\", \"com.mysql.jdbc.Driver\")\\\n",
    "      .option(\"url\", \"jdbc:mysql://<ip>:3306/<dbname>\")\\\n",
    "      .option(\"dbtable\", \"<table name>\")\\\n",
    "      .option(\"user\", \" <username>\")\\\n",
    "      .option(\"password\",\"<password>\")\\\n",
    "      .load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-14T18:53:31.345614Z",
     "start_time": "2019-03-14T18:53:31.343438Z"
    }
   },
   "source": [
    "#### Write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write\\\n",
    "      .format(\"jdbc\")\\\n",
    "      .option(\"driver\", \"com.mysql.jdbc.Driver\")\\\n",
    "      .option(\"url\", \"jdbc:mysql://<ip>:3306/<dbname>\")\\\n",
    "      .option(\"dbtable\", \"<table name>\")\\\n",
    "      .option(\"user\", \" <username>\")\\\n",
    "      .option(\"password\",\"<password>\")\\\n",
    "      .mode(\"overwrite\")\\\n",
    "      .save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-14T18:54:42.243291Z",
     "start_time": "2019-03-14T18:54:42.226100Z"
    }
   },
   "source": [
    "# NoSQL Databases\n",
    "\n",
    "|Source| Driver Package|Format Name|Standard Port|\n",
    "|-----------|----------------|---------|----|\n",
    "|Cassandra  |com.datastax.spark:spark-cassandra-connector_2.11:2.3.0|org.apache.spark.sql.cassandra|9042\n",
    "|DynamoDB   |com.amazon.emr:emr-dynamodb-hadoop:4.2.0|\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cassandra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.read.format(\"org.apache.spark.sql.cassandra\")\\\n",
    "          .option(\"spark.cassandra.connection.host\",\"<ip>\")\\\n",
    "          .option(\"spark.cassandra.connection.port\",\"<port>\")\\\n",
    "          .option(\"keyspace\",\"<keyspace name>\")\\\n",
    "          .option(\"table\",\"<table name>\")\n",
    "          .load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.write.format(\"org.apache.spark.sql.cassandra\")\\\n",
    "          .option(\"spark.cassandra.connection.host\",\"<ip>\")\\\n",
    "          .option(\"spark.cassandra.connection.port\",\"<port>\")\\\n",
    "          .option(\"keyspace\",\"<keyspace name>\")\\\n",
    "          .option(\"table\",\"<table name>\")\n",
    "          .save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-13T20:47:54.747079Z",
     "start_time": "2019-03-13T20:47:54.740049Z"
    }
   },
   "source": [
    "## Dynamo DB (TODO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
